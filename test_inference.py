# -*- coding: utf-8 -*-
"""
Fun-CosyVoice3-0.5B-2512 æœ¬åœ°æ¨ç†æµ‹è¯•
éªŒè¯æ¨¡å‹åŠ è½½å’Œ GPU æ˜¾å­˜å ç”¨
ä½œè€…ï¼šå‡Œå°
æ¥æºï¼šhttps://aibook.ren (AIå…¨ä¹¦)
"""
import os
import sys
import time
import argparse

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, SCRIPT_DIR)
sys.path.insert(0, os.path.join(SCRIPT_DIR, 'third_party', 'Matcha-TTS'))

import torch
import torchaudio
import numpy as np



# è®¾ç½® cuDNN åº“è·¯å¾„ (ONNX Runtime GPU åŠ é€Ÿ)
try:
    import nvidia.cudnn
    cudnn_lib = os.path.join(nvidia.cudnn.__path__[0], 'lib')
    if os.path.isdir(cudnn_lib):
        os.environ['LD_LIBRARY_PATH'] = f"{cudnn_lib}:{os.environ.get('LD_LIBRARY_PATH', '')}"
except ImportError:
    pass

def main():
    parser = argparse.ArgumentParser(description="CosyVoice æ¨ç†æµ‹è¯•")
    parser.add_argument("--use_vllm", action="store_true", help="ä½¿ç”¨ vLLM åŠ é€Ÿ")
    args = parser.parse_args()
    
    print("=" * 60)
    print("Fun-CosyVoice3-0.5B-2512 æœ¬åœ°æ¨ç†æµ‹è¯•")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ GPU
    print("\n[1/4] æ£€æŸ¥ GPU ç¯å¢ƒ")
    if torch.cuda.is_available():
        print(f"  âœ“ GPU: {torch.cuda.get_device_name(0)}")
        print(f"  âœ“ CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  âœ“ åˆå§‹æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f}GB")
    else:
        print("  âš  æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU æ¨ç† (é€Ÿåº¦è¾ƒæ…¢)")
    
    # 2. åŠ è½½æ¨¡å‹
    print("\n[2/4] åŠ è½½æ¨¡å‹")
    model_dir = os.path.join(SCRIPT_DIR, "models", "Fun-CosyVoice3-0.5B")
    
    if not os.path.exists(os.path.join(model_dir, "cosyvoice3.yaml")):
        print(f"  âœ— æ¨¡å‹æœªæ‰¾åˆ°: {model_dir}")
        print("  è¯·å…ˆè¿è¡Œ: python download_model.py")
        return
    
    from cosyvoice.cli.cosyvoice import AutoModel
    
    start_time = time.time()
    print(f"  > vLLM åŠ é€Ÿ: {'å·²å¯ç”¨ (utilization=0.2)' if args.use_vllm else 'æœªå¯ç”¨'}")
    
    try:
        cosyvoice = AutoModel(model_dir=model_dir, load_vllm=args.use_vllm)
    except Exception as e:
        print(f"  âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        if args.use_vllm:
             print("  è¯·æ£€æŸ¥æ˜¯å¦å·²å®‰è£… vllm: pip install vllm==0.9.0")
        return

    load_time = time.time() - start_time
    
    print(f"  âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.1f}s")
    print(f"  âœ“ é‡‡æ ·ç‡: {cosyvoice.sample_rate}Hz")
    
    if torch.cuda.is_available():
        print(f"  âœ“ æ¨¡å‹åŠ è½½åæ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f}GB")
    
    # 3. æ£€æŸ¥å‚è€ƒéŸ³é¢‘
    print("\n[3/4] åŠ è½½å‚è€ƒéŸ³é¢‘")
    prompt_wav_path = os.path.join(SCRIPT_DIR, "official", "asset", "zero_shot_prompt.wav")
    
    if not os.path.exists(prompt_wav_path):
        prompt_wav_path = os.path.join(SCRIPT_DIR, "asset", "prompt.wav")
    
    if os.path.exists(prompt_wav_path):
        print(f"  âœ“ å‚è€ƒéŸ³é¢‘: {prompt_wav_path}")
    else:
        print(f"  âš  æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘ï¼Œè·³è¿‡æ¨ç†æµ‹è¯•")
        return
    
    # CosyVoice3 éœ€è¦ "You are a helpful assistant.<|endofprompt|>" å‰ç¼€
    prompt_text = "You are a helpful assistant.<|endofprompt|>å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
    
    # 4. æ¨ç†æµ‹è¯•
    print("\n[4/4] æ¨ç†æµ‹è¯•")
    
    test_sentences = [
        "ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ™ºï¼Œä½ çš„æ™ºèƒ½åŠ©æ‰‹",
        "æœ‰å•¥éœ€è¦æˆ‘å¸®å¿™çš„å—ï¼Ÿ",
        "æµ™æ±Ÿçœçš„çœä¼šæ˜¯æ­å·å¸‚ã€‚",
        "çœ‹æ¥ä½ æœ‰åˆ«çš„äº‹æƒ…è¦å¿™ï¼Œæˆ‘å…ˆèµ°å•¦ï¼Œéœ€è¦æˆ‘æ—¶å†å‘¼å”¤æˆ‘å“¦"
    ]

    output_dir = os.path.join(SCRIPT_DIR, "output")
    os.makedirs(output_dir, exist_ok=True)

    # [é‡è¦ä¼˜åŒ–] é¢„å…ˆè®¡ç®—å¹¶ç¼“å­˜éŸ³è‰²ç‰¹å¾
    # è¿™ä¸€æ­¥ä¼šæ‰§è¡Œ load_wav, extract_feat ç­‰è€—æ—¶æ“ä½œï¼Œå¹¶å°†ç»“æœå­˜å…¥ spk2info
    print(f"  æ­£åœ¨é¢„è®¡ç®—å¹¶ç¼“å­˜å‚è€ƒéŸ³é¢‘ç‰¹å¾ (ID: test_user)...")
    cosyvoice.add_zero_shot_spk(prompt_text, prompt_wav_path, "test_user")
    
    for idx, test_text in enumerate(test_sentences):
        print(f"\n[{idx+1}/{len(test_sentences)}] æµ‹è¯•æ–‡æœ¬: {test_text}")
        print("-" * 50)
        
        start_time = time.time()
        first_chunk_time = None
        total_samples = 0
        audio_chunks = []
        
        # [ä¼˜åŒ–] ä½¿ç”¨ zero_shot_spk_id è°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜ç‰¹å¾ï¼Œè·³è¿‡ I/O å’Œç‰¹å¾æå–
        for i, result in enumerate(cosyvoice.inference_zero_shot(
            test_text, 
            prompt_text, 
            prompt_wav_path, # æ­¤å‚æ•°å°†è¢«å¿½ç•¥
            stream=True,
            zero_shot_spk_id="test_user"
        )):
            if first_chunk_time is None:
                first_chunk_time = time.time() - start_time
            
            audio_tensor = result['tts_speech']
            audio_chunks.append(audio_tensor)
            total_samples += audio_tensor.shape[-1]
            
            # [æ¨¡æ‹ŸæœåŠ¡ç«¯ä¼˜åŒ–] GPU PCM è½¬æ¢
            _ = (audio_tensor * 32768).to(torch.int16).cpu().numpy().tobytes()
        
        total_time = time.time() - start_time
        audio_duration = total_samples / cosyvoice.sample_rate
        rtf = total_time / audio_duration if audio_duration > 0 else 0
        
        # æ‰“å°ç»“æœ
        print(f"  âš¡ é¦–å¸§å»¶è¿Ÿ: \033[1;32m{first_chunk_time * 1000:.0f} ms\033[0m" if first_chunk_time else "  âš¡ é¦–å¸§å»¶è¿Ÿ: N/A")
        print(f"  â±ï¸  æ€»è€—æ—¶:   {total_time:.3f} s")
        print(f"  ğŸµ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} s")
        print(f"  ğŸš€ RTF:      {rtf:.3f}")
        
        # ä¿å­˜éŸ³é¢‘
        if audio_chunks:
            # import torch # å·²åœ¨å…¨å±€å¯¼å…¥
            full_audio = torch.cat(audio_chunks, dim=-1)
            filename = f"test_output_{idx+1}.wav"
            output_path = os.path.join(output_dir, filename)
            torchaudio.save(output_path, full_audio, cosyvoice.sample_rate)
            print(f"  ğŸ’¾ å·²ä¿å­˜:   {filename}")
    
    if torch.cuda.is_available():
        print(f"\n  âœ“ æ¨ç†åæ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f}GB")
        print(f"  âœ“ æ˜¾å­˜å³°å€¼: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f}GB")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
